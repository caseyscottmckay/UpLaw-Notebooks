{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of my results:\n",
    "\n",
    "model            | train_loss | valid_loss | seq2seq_acc | bleu\n",
    "-------------------|----------|----------|----------|----------\n",
    "seq2seq            | 3.355085 | 4.272877 | 0.382089 | 0.291899\n",
    "\\+ teacher forcing | 3.154585 |\t4.022432 | 0.407792 | 0.310715\n",
    "\\+ attention       | 1.452292 | 3.420485 | 0.498205 | 0.413232\n",
    "transformer        | 1.913152 | 2.349686 | 0.781749 | 0.612880"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation with an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is modified from [this one](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/translation.ipynb) created by Sylvain Gugger.\n",
    "\n",
    "Today we will be tackling the task of translation. We will be translating from French to English, and to keep our task a manageable size, we will limit ourselves to translating questions.\n",
    "\n",
    "This task is an example of sequence to sequence (seq2seq). Seq2seq can be more challenging than classification, since the output is of variable length (and typically different from the length of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French/English parallel texts from http://www.statmt.org/wmt15/translation-task.html .  It was created by Chris Callison-Burch, who crawled millions of web pages and then used *a set of simple heuristics to transform French URLs onto English URLs (i.e. replacing \"fr\" with \"en\" and about 40 other hand-written rules), and assume that these documents are translations of each other*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation is much tougher in straight PyTorch: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by reducing the original dataset to questions. You only need to execute this once, uncomment to run. The dataset can be downloaded [here](https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Config().data_path()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! wget https://s3.amazonaws.com/fast-ai-nlp/giga-fren.tgz -P {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! tar xf {path}/giga-fren.tgz -C {path} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/jupyter/data/eng-fra-data/fr_emb.pth'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/data_save.pkl'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/eng-fra.txt'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/models'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/.ipynb_checkpoints'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/en_emb.pth'),\n",
       " PosixPath('/home/jupyter/data/eng-fra-data/names')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Config().data_path()/'eng-fra-data'\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path/'giga-fren.release2.fixed.fr') as f: fr = f.read().split('\\n')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(path/'giga-fren.release2.fixed.en') as f: en = f.read().split('\\n')[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use regex to pick out questions by finding the strings in the English dataset that start with \"Wh\" and end with a question mark.  You only need to run these lines once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "#re_fq = re.compile('^([^?.!]+\\?)')\n",
    "#en_fname = path/'giga-fren.release2.fixed.en'\n",
    "#fr_fname = path/'giga-fren.release2.fixed.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "#    for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "#qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qs = [(q1,q2) for q1,q2 in qs]\n",
    "#df = pd.DataFrame({'fr': [q[1] for q in qs], 'en': [q[0] for q in qs]}, columns = ['en', 'fr'])\n",
    "#df.to_csv(path/'questions_easy.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load our data into a DataBunch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our questions look like this now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0           1     en          fr\n",
       "0    Go.        Va !    Go.        Va !\n",
       "1   Run!     Cours !   Run!     Cours !\n",
       "2   Run!    Courez !   Run!    Courez !\n",
       "3   Wow!  Ça alors !   Wow!  Ça alors !\n",
       "4  Fire!    Au feu !  Fire!    Au feu !"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(path/'questions_easy.csv')\n",
    "import pandas as pd\n",
    "df = pd.read_csv('~/data/eng-fra-data/eng-fra.txt', sep='\\t', header=None)\n",
    "df['en']=df[0]\n",
    "df['fr']=df[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it simple, we lowercase everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en'] = df['en'].apply(lambda x:x.lower())\n",
    "df['fr'] = df['fr'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is that we will need to collate inputs and targets in a batch: they have different lengths so we need to add padding to make the sequence length the same;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a special `DataBunch` that uses this collate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"Dataset\" class=\"doc_header\"><code>class</code> <code>Dataset</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>Dataset</code>()</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"Dataset-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#Dataset-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>Dataset</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>An abstract class representing a :class:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\"><code>Dataset</code></a>. All datasets that represent a map from keys to data samples should subclass\n",
       "it. All subclasses should overrite :meth:<code>__getitem__</code>, supporting fetching a\n",
       "data sample for a given key. Subclasses could also optionally overwrite\n",
       ":meth:<code>__len__</code>, which is expected to return the size of the dataset by many\n",
       ":class:<code>~torch.utils.data.Sampler</code> implementations and the default options\n",
       "of :class:<code>~torch.utils.data.DataLoader</code>.</p>\n",
       "<p>.. note::\n",
       "  :class:<code>~torch.utils.data.DataLoader</code> by default constructs a index\n",
       "  sampler that yields integral indices.  To make it work with a map-style\n",
       "  dataset with non-integral indices/keys, a custom sampler must be provided.</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"DataLoader\" class=\"doc_header\"><code>class</code> <code>DataLoader</code><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataLoader</code>(<strong><code>dataset</code></strong>, <strong><code>batch_size</code></strong>=<strong><em><code>1</code></em></strong>, <strong><code>shuffle</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>batch_sampler</code></strong>=<strong><em><code>None</code></em></strong>, <strong><code>num_workers</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>collate_fn</code></strong>=<strong><em><code>'default_collate'</code></em></strong>, <strong><code>pin_memory</code></strong>=<strong><em><code>True</code></em></strong>, <strong><code>drop_last</code></strong>=<strong><em><code>False</code></em></strong>, <strong><code>timeout</code></strong>=<strong><em><code>0</code></em></strong>, <strong><code>worker_init_fn</code></strong>=<strong><em><code>None</code></em></strong>)</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"DataLoader-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataLoader-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>DataLoader</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.</p>\n",
       "<p>The :class:<code>~torch.utils.data.DataLoader</code> supports both map-style and\n",
       "iterable-style datasets with single- or multi-process loading, customizing\n",
       "loading order and optional automatic batching (collation) and memory pinning.</p>\n",
       "<p>See :py:mod:<a href=\"https://pytorch.org/docs/stable/data.html#module-torch.utils.data\"><code>torch.utils.data</code></a> documentation page for more details.</p>\n",
       "<p>Arguments:\n",
       "    dataset (Dataset): dataset from which to load the data.\n",
       "    batch_size (int, optional): how many samples per batch to load\n",
       "        (default: <code>1</code>).\n",
       "    shuffle (bool, optional): set to <code>True</code> to have the data reshuffled\n",
       "        at every epoch (default: <code>False</code>).\n",
       "    sampler (Sampler, optional): defines the strategy to draw samples from\n",
       "        the dataset. If specified, :attr:<code>shuffle</code> must be <code>False</code>.\n",
       "    batch_sampler (Sampler, optional): like :attr:<code>sampler</code>, but returns a batch of\n",
       "        indices at a time. Mutually exclusive with :attr:<code>batch_size</code>,\n",
       "        :attr:<code>shuffle</code>, :attr:<code>sampler</code>, and :attr:<code>drop_last</code>.\n",
       "    num_workers (int, optional): how many subprocesses to use for data\n",
       "        loading. <code>0</code> means that the data will be loaded in the main process.\n",
       "        (default: <code>0</code>)\n",
       "    collate_fn (callable, optional): merges a list of samples to form a\n",
       "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
       "        map-style dataset.\n",
       "    pin_memory (bool, optional): If <code>True</code>, the data loader will copy Tensors\n",
       "        into CUDA pinned memory before returning them.  If your data elements\n",
       "        are a custom type, or your :attr:<code>collate_fn</code> returns a batch that is a custom type,\n",
       "        see the example below.\n",
       "    drop_last (bool, optional): set to <code>True</code> to drop the last incomplete batch,\n",
       "        if the dataset size is not divisible by the batch size. If <code>False</code> and\n",
       "        the size of dataset is not divisible by the batch size, then the last batch\n",
       "        will be smaller. (default: <code>False</code>)\n",
       "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
       "        from workers. Should always be non-negative. (default: <code>0</code>)\n",
       "    worker_init_fn (callable, optional): If not <code>None</code>, this will be called on each\n",
       "        worker subprocess with the worker id (an int in <code>[0, num_workers - 1]</code>) as\n",
       "        input, after seeding and before data loading. (default: <code>None</code>)</p>\n",
       "<p>.. warning:: If the <code>spawn</code> start method is used, :attr:<code>worker_init_fn</code>\n",
       "             cannot be an unpicklable object, e.g., a lambda function. See\n",
       "             :ref:<code>multiprocessing-best-practices</code> on more details related\n",
       "             to multiprocessing in PyTorch.</p>\n",
       "<p>.. note:: <code>len(dataloader)</code> heuristic is based on the length of the sampler used.\n",
       "          When :attr:<code>dataset</code> is an :class:<code>~torch.utils.data.IterableDataset</code>,\n",
       "          an infinite sampler is used, whose :meth:<code>__len__</code> is not\n",
       "          implemented, because the actual length depends on both the\n",
       "          iterable as well as multi-process loading configurations. So one\n",
       "          should not query this method unless they work with a map-style\n",
       "          dataset. See <code>Dataset Types</code>_ for more details on these two types\n",
       "          of datasets.</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 id=\"DataBunch\" class=\"doc_header\"><code>class</code> <code>DataBunch</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/basic_data.py#L84\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h2><blockquote><p><code>DataBunch</code>(<strong><code>train_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>valid_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>, <strong><code>fix_dl</code></strong>:<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>test_dl</code></strong>:<code>Optional</code>[<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\"><code>DataLoader</code></a>]=<strong><em><code>None</code></em></strong>, <strong><code>device</code></strong>:<a href=\"https://pytorch.org/docs/stable/tensor_attributes.html#torch-device\"><code>device</code></a>=<strong><em><code>None</code></em></strong>, <strong><code>dl_tfms</code></strong>:<code>Optional</code>[<code>Collection</code>[<code>Callable</code>]]=<strong><em><code>None</code></em></strong>, <strong><code>path</code></strong>:<code>PathOrStr</code>=<strong><em><code>'.'</code></em></strong>, <strong><code>collate_fn</code></strong>:<code>Callable</code>=<strong><em><code>'data_collate'</code></em></strong>, <strong><code>no_check</code></strong>:<code>bool</code>=<strong><em><code>False</code></em></strong>)</p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"DataBunch-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#DataBunch-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>Tests found for <code>DataBunch</code>:</p><ul><li><code>pytest -sv tests/test_data_block.py::test_custom_dataset</code> <a href=\"https://github.com/fastai/fastai/blob/master/tests/test_data_block.py#L152\" class=\"source_link\" style=\"float:right\">[source]</a></li></ul><p>To run tests please refer to this <a href=\"/dev/test.html#quick-guide\">guide</a>.</p></div></div><p>Bind <code>train_dl</code>,<code>valid_dl</code> and <code>test_dl</code> in a data object.</p>\n",
       "<p><a href=\"https://docs.fast.ai/basic_data.html#DataBunch\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(DataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mSortishSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_source\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mSortishSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"Go through the text data by order of length with a bit of randomness.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mNPArrayList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mKeyFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mck_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msort_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mck_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mck_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmax_ck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mck\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mck_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# find the chunk with the largest key,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_ck\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_ck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# then make sure it goes first.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msort_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msort_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mck_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/anaconda3/lib/python3.7/site-packages/fastai/text/data.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SortishSampler??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a subclass of `TextList` that will use this `DataBunch` class in the call `.databunch` and will use `TextList` to label (since our targets are other texts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch\n",
    "    _label_cls = TextList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats all we need to use the data block API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src = Seq2SeqTextList.from_df(df, path = path, cols='fr').split_by_rand_pct(seed=42).label_from_df(cols='en', label_cls=TextList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in src.train.x.items] + [len(o) for o in src.valid.x.items], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in src.train.y.items] + [len(o) for o in src.valid.y.items], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the items where one of the target is more than 30 tokens long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src.filter_by_func(lambda x,y: len(x) > 30 or len(y) > 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135791"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src.train) + len(src.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = src.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqDataBunch;\n",
       "\n",
       "Train: LabelList (108632 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos cours   !,xxbos courez   !,xxbos ça alors   !,xxbos à l'aide   !,xxbos saute .\n",
       "y: TextList\n",
       "xxbos run !,xxbos run !,xxbos wow !,xxbos help !,xxbos jump .\n",
       "Path: /home/jupyter/data/eng-fra-data;\n",
       "\n",
       "Valid: LabelList (27159 items)\n",
       "x: Seq2SeqTextList\n",
       "xxbos le vent était tellement fort que nous avons presque été xxunk en dehors de la route .,xxbos tu ne peux jamais être heureux si tu te sens envieux à l'égard xxunk .,xxbos xxunk le problème !,xxbos cessez , je vous prie !,xxbos vous êtes celui - là .\n",
       "y: TextList\n",
       "xxbos the wind was so strong , we were nearly blown off the road .,xxbos you can never be happy if you feel envious of other people .,xxbos let 's reconsider the problem .,xxbos stop it , please .,xxbos you are the one .\n",
       "Path: /home/jupyter/data/eng-fra-data;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/data/eng-fra-data')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos conformément au contrat , vous pouvez prendre trois jours de congé de décès pour les funérailles de votre oncle , mais un seul pour celles de votre neveu .</td>\n",
       "      <td>xxbos according to the contract you may take three days of bereavement leave for your uncle 's funeral , but only one for your nephew 's .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos de toutes les choses que tom a faites le week - end dernier , il dit que la planche à voile était la plus amusante .</td>\n",
       "      <td>xxbos of all the things tom did last weekend , he says that xxunk was the most fun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos je ne vois jamais une bibliothèque sans souhaiter avoir le temps de m'y rendre et d'y rester jusqu'à ce que j'y aie tout lu .</td>\n",
       "      <td>xxbos i never see a library without xxunk i had time to go there and stay till i had read everything in it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos nous irons au cinéma , la prochaine fois . \" qu'est - ce qui vous fait penser qu'il y aura une prochaine fois ? \"</td>\n",
       "      <td>xxbos let 's go to the movies next time . \" what makes you think there will be a next time ? \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos il y a deux sortes de travail dans le monde : celui de la tête et celui des mains ; xxunk et manuel .</td>\n",
       "      <td>xxbos there are two kinds of work in the world xxunk head work and hand work ; mental and manual .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to download the word embeddings (crawl vectors) from the fastText docs. FastText has [pre-trained word vectors](https://fasttext.cc/docs/en/crawl-vectors.html) for 157 languages, trained on Common Crawl and Wikipedia. These models were trained using CBOW.\n",
    "\n",
    "If you need a refresher on word embeddings, you can check out my gentle intro in [this word embedding workshop](https://www.youtube.com/watch?v=25nC0n9ERq4&list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&index=10&t=0s) with accompanying [github repo](https://github.com/fastai/word-embeddings-workshop). \n",
    "\n",
    "More reading on CBOW (Continuous Bag of Words vs. Skip-grams):\n",
    "\n",
    "- [fastText tutorial](https://fasttext.cc/docs/en/unsupervised-tutorial.html#advanced-readers-skipgram-versus-cbow)\n",
    "- [StackOverflow](https://stackoverflow.com/questions/38287772/cbow-v-s-skip-gram-why-invert-context-and-target-words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install fastText:\n",
    "```\n",
    "$ git clone https://github.com/facebookresearch/fastText.git\n",
    "$ cd fastText\n",
    "$ pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/anaconda3/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from fasttext) (41.4.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/anaconda3/lib/python3.7/site-packages (from fasttext) (2.4.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from fasttext) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "import fasttext as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines to download the word vectors only need to be run once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz -P {path}\n",
    "# ! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz -P {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gunzip {path} / cc.en.300.bin.gz\n",
    "# gunzip {path} / cc.fr.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fr_vecs = ft.load_model(str(('/home/jupyter/data/cc.fr.300.bin')))\n",
    "en_vecs = ft.load_model(str(('/home/jupyter/data/cc.en.300.bin')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an embedding module with the pretrained vectors and random data for the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz=300, mult=1.):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    vec_dic = {w:vecs.get_word_vector(w) for w in vecs.get_words()}\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = tensor(vec_dic[w])\n",
    "        except: miss.append(w)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = create_emb(fr_vecs, data.x.vocab.itos)\n",
    "emb_dec = create_emb(en_vecs, data.y.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10464, 300]), torch.Size([6512, 300]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_enc.weight.size(), emb_dec.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Config().model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(emb_enc, path/'fr_emb.pth')\n",
    "torch.save(emb_dec, path/'en_emb.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = torch.load(path/'fr_emb.pth')\n",
    "emb_dec = torch.load(path/'en_emb.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review Question: What are the two types of numbers in deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoders & Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in itself consists in an encoder and a decoder\n",
    "\n",
    "![Seq2seq model](images/seq2seq.png)\n",
    "\n",
    "<center><i>Diagram from Smerity's <a href=\"https://smerity.com/articles/2016/google_nmt_arch.html\">Peeking into the neural network architecture used for Google's Neural Machine Translation</a></i></center>\n",
    "\n",
    "The encoder is a recurrent neural net and we feed it our input sentence, producing an output (that we discard for now) and a hidden state.  A **hidden state** is the activations that come out of an RNN.\n",
    "\n",
    "That hidden state is then given to the decoder (an other RNN) which uses it in conjunction with the outputs it predicts to get produce the translation. We loop until the decoder produces a padding token (or at 30 iterations to make sure it's not an infinite loop at the beginning of training). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a GRU for our encoder and a separate GRU for our decoder. Other options are to use LSTMs or QRNNs (see here).  GRUs, LSTMs, and QRNNs all solve the problem of how RNNs can lack long-term memory.\n",
    "\n",
    "Links:\n",
    "- [Illustrated Guide to LSTM’s and GRU’s: A step by step explanation](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n",
    "- [fast.ai implementation of seq2seq with QRNNs](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/translation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, \n",
    "                    nh, out_sl, \n",
    "                    nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.em_sz_enc = emb_enc.embedding_dim\n",
    "        self.em_sz_dec = emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl,\n",
    "                              dropout=0.25, batch_first=True)\n",
    "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = emb_dec\n",
    "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        _, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        return h\n",
    "    \n",
    "    def decoder(self, dec_inp, h):\n",
    "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "        outp, h = self.gru_dec(emb, h)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return h, outp\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        bs, sl = inp.size()\n",
    "        h = self.encoder(bs, inp)\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            h, outp = self.decoder(dec_inp, h)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            res.append(outp)\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "        return torch.stack(res, dim=1)\n",
    "    \n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(self.nl, bs, self.nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(data.valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN(emb_enc, emb_dec, 256, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqRNN(\n",
       "  (emb_enc): Embedding(10464, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
       "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (out_enc): Linear(in_features=256, out_features=300, bias=False)\n",
       "  (emb_dec): Embedding(6512, 300, padding_idx=1)\n",
       "  (gru_dec): GRU(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (out_drop): Dropout(p=0.35, inplace=False)\n",
       "  (out): Linear(in_features=300, out_features=6512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = rnn.encoder(64, xb.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 300])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss pads output and target so that they are of the same size before using the usual flattened version of cross entropy. We do the same for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    return CrossEntropyFlat()(out, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, rnn, loss_func=seq2seq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.063637</td>\n",
       "      <td>2.667045</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.657815</td>\n",
       "      <td>2.025264</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.530175</td>\n",
       "      <td>2.453182</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.473664</td>\n",
       "      <td>2.460207</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's free up some RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fr_vecs\n",
    "del en_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As loss is not very interpretable, let's also look at the accuracy.  Again, we will add padding so that the output and target are of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_acc(out, targ, pad_idx=1):\n",
    "    bs,targ_len = targ.size()\n",
    "    _,out_len,vs = out.size()\n",
    "    if targ_len>out_len: out  = F.pad(out,  (0,0,0,targ_len-out_len,0,0), value=pad_idx)\n",
    "    if out_len>targ_len: targ = F.pad(targ, (0,out_len-targ_len,0,0), value=pad_idx)\n",
    "    out = out.argmax(2)\n",
    "    return (out==targ).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bleu metric (see dedicated notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In translation, the metric usually used is BLEU.\n",
    "\n",
    "A great post by Rachael Tatman: [Evaluating Text Output in NLP: BLEU at your own risk](https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGram():\n",
    "    def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "    def __eq__(self, other):\n",
    "        if len(self.ngram) != len(other.ngram): return False\n",
    "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "    def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grams(x, n, max_n=5000):\n",
    "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
    "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
    "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "    return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBLEU(Callback):\n",
    "    def __init__(self, vocab_sz):\n",
    "        self.vocab_sz = vocab_sz\n",
    "        self.name = 'bleu'\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        last_output = last_output.argmax(dim=-1)\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "        len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "        bleu = len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)\n",
    "        return add_metrics(last_metrics, bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, rnn, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.767991</td>\n",
       "      <td>3.120510</td>\n",
       "      <td>0.489786</td>\n",
       "      <td>0.300205</td>\n",
       "      <td>02:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.889867</td>\n",
       "      <td>3.076199</td>\n",
       "      <td>0.496212</td>\n",
       "      <td>0.305587</td>\n",
       "      <td>02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.616363</td>\n",
       "      <td>3.182902</td>\n",
       "      <td>0.471185</td>\n",
       "      <td>0.308751</td>\n",
       "      <td>02:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.536122</td>\n",
       "      <td>2.772401</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>01:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.606913</td>\n",
       "      <td>2.558938</td>\n",
       "      <td>0.544116</td>\n",
       "      <td>0.342630</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.381359</td>\n",
       "      <td>2.756686</td>\n",
       "      <td>0.518783</td>\n",
       "      <td>0.334313</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.368385</td>\n",
       "      <td>2.603505</td>\n",
       "      <td>0.538325</td>\n",
       "      <td>0.345629</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.338424</td>\n",
       "      <td>2.584584</td>\n",
       "      <td>0.540696</td>\n",
       "      <td>0.348304</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how good is our model? Let's see a few predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(learn, ds_type=DatasetType.Valid):\n",
    "    learn.model.eval()\n",
    "    inputs, targets, outputs = [],[],[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in progress_bar(learn.dl(ds_type)):\n",
    "            out = learn.model(xb)\n",
    "            for x,y,z in zip(xb,yb,out):\n",
    "                inputs.append(learn.data.train_ds.x.reconstruct(x))\n",
    "                targets.append(learn.data.train_ds.y.reconstruct(y))\n",
    "                outputs.append(learn.data.train_ds.y.reconstruct(z.argmax(1)))\n",
    "    return inputs, targets, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='425' class='' max='425', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [425/425 00:50<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos quels sont les aliments qu'on mange habituellement avec de la sauce de soja   ?,\n",
       " Text xxbos what are some foods you usually eat with soy sauce ?,\n",
       " Text xxbos what are are foods foods eat eat ? ?)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[700], targets[700], outputs[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos je ne pense pas que ça me dérangerait de manger chinois tous les jours .,\n",
       " Text xxbos i do n't think i 'd mind eating chinese food every day .,\n",
       " Text xxbos i do n't think eat eat eat eat eat)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[701], targets[701], outputs[701]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos j'ai écouté mais je n'ai pas pu distinguer ce qu'ils xxunk .,\n",
       " Text xxbos i listened but could n't make out what they were saying .,\n",
       " Text xxbos i could could could could could could could but could could could could)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[2513], targets[2513], outputs[2513]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos il y a beaucoup de tremblements de terre au japon .,\n",
       " Text xxbos we have a lot of earthquakes in japan .,\n",
       " Text xxbos there is many lot lot of . .)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[4000], targets[4000], outputs[4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's usually beginning well, but falls into repeated words at the end of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to help training is to help the decoder by feeding it the real targets instead of its predictions (if it starts with wrong words, it's very unlikely to give us the right translation). We do that all the time at the beginning, then progressively reduce the amount of teacher forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherForcing(LearnerCallback):\n",
    "    \n",
    "    def __init__(self, learn, end_epoch):\n",
    "        super().__init__(learn)\n",
    "        self.end_epoch = end_epoch\n",
    "    \n",
    "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
    "        if train: return {'last_input': [last_input, last_target]}\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, **kwargs):\n",
    "        self.learn.model.pr_force = 1 - epoch/self.end_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the following code to our `forward` method:\n",
    "\n",
    "```\n",
    "    if (targ is not None) and (random.random()<self.pr_force):\n",
    "        if i>=targ.shape[1]: break\n",
    "        dec_inp = targ[:,i]\n",
    "```\n",
    "Additionally, `forward` will take an additional argument of `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_tf(nn.Module):\n",
    "    def __init__(self, emb_enc, emb_dec, nh, out_sl, nl=2, bos_idx=0, pad_idx=1):\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.bos_idx,self.pad_idx = bos_idx,pad_idx\n",
    "        self.em_sz_enc = emb_enc.embedding_dim\n",
    "        self.em_sz_dec = emb_dec.embedding_dim\n",
    "        self.voc_sz_dec = emb_dec.num_embeddings\n",
    "                 \n",
    "        self.emb_enc = emb_enc\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(self.em_sz_enc, nh, num_layers=nl,\n",
    "                              dropout=0.25, batch_first=True)\n",
    "        self.out_enc = nn.Linear(nh, self.em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = emb_dec\n",
    "        self.gru_dec = nn.GRU(self.em_sz_dec, self.em_sz_dec, num_layers=nl,\n",
    "                              dropout=0.1, batch_first=True)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(self.em_sz_dec, self.voc_sz_dec)\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 0.\n",
    "        \n",
    "    def encoder(self, bs, inp):\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        _, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        return h\n",
    "    \n",
    "    def decoder(self, dec_inp, h):\n",
    "        emb = self.emb_dec(dec_inp).unsqueeze(1)\n",
    "        outp, h = self.gru_dec(emb, h)\n",
    "        outp = self.out(self.out_drop(outp[:,0]))\n",
    "        return h, outp\n",
    "            \n",
    "    def forward(self, inp, targ=None):\n",
    "        bs, sl = inp.size()\n",
    "        h = self.encoder(bs, inp)\n",
    "        dec_inp = inp.new_zeros(bs).long() + self.bos_idx\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            h, outp = self.decoder(dec_inp, h)\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.max(1)[1]\n",
    "            if (dec_inp==self.pad_idx).all(): break\n",
    "            if (targ is not None) and (random.random()<self.pr_force):\n",
    "                if i>=targ.shape[1]: continue\n",
    "                dec_inp = targ[:,i]\n",
    "        return torch.stack(res, dim=1)\n",
    "\n",
    "    def initHidden(self, bs): return one_param(self).new_zeros(self.nl, bs, self.nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_enc = torch.load(path/'fr_emb.pth')\n",
    "emb_dec = torch.load(path/'en_emb.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tf = Seq2SeqRNN_tf(emb_enc, emb_dec, 256, 30)\n",
    "\n",
    "learn = Learner(data, rnn_tf, loss_func=seq2seq_loss, metrics=[seq2seq_acc, CorpusBLEU(len(data.y.vocab.itos))],\n",
    "               callback_fns=partial(TeacherForcing, end_epoch=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZhcVb3u8e+vqnqe0kl3BjInzEQZ0mGUURD0eAVEFDw8gqJcRfGqD3r04j3nqA9HVBRxFjWAF4iXyXNED8gkIBgInRBCgEASyNCZupOe566qdf+o3Z1Ok0562rVrV72f56mnqnbtqrVWdufdu9ZetbY55xARkdwRCboCIiKSXgp+EZEco+AXEckxCn4RkRyj4BcRyTGxoCswElVVVW7evHlBV0NEJFRWrly52zlXPXR5KIJ/3rx51NbWBl0NEZFQMbPN+1uurh4RkRyj4BcRyTEKfhGRHKPgFxHJMQp+EZEco+AXEckxCn4RkRyj4BcRyUBdvQm+9dCrbG3snPDPVvCLiGSg+1du5fbnNrGjpXvCP1vBLyKSYRJJx2/+/jbHzZ7EknmVE/75vgW/mS01s3ozWztk+XVm9oaZvWpm3/erfBGRsHpk7U62NHby2TMXYGYT/vl+HvHfAVwweIGZnQ1cCLzbOXcMcLOP5YuIhI5zjl8/s5H5VSWcd/R0X8rwLfidc88AjUMWfw64yTnX461T71f5IiJh9Pxbjaypa+HTp88nGpn4o31Ifx//4cDpZvaCmT1tZkuGW9HMrjGzWjOrbWhoSGMVRUSC8+tnNlJVms8lJ8zyrYx0B38MqAROBr4K3GvDdGA5525zztU452qqq98xnbSISNZZt7OVp95o4KpT51GYF/WtnHQHfx3woEtZASSBqjTXQUQkI932zFsU50e54uS5vpaT7uD/T+AcADM7HMgHdqe5DiIiGWd7cxd/Wr2djy2ZzaTifF/L8u0KXGa2DDgLqDKzOuDfgKXAUm+IZy9wpXPO+VUHEZGweGBlHQnnuPo9830vy7fgd85dPsxLV/hVpohIWL2+s5W5k4uZVVnse1n65a6ISAbYUN/OoVNL01KWgl9EJGDxRJK3d3ewUMEvIpIbtjR20pdwHFqt4BcRyQkb6tsB1NUjIpIrNjSkgl9dPSIiOWJDfTvTygsoL8xLS3kKfhGRgG1M44geUPCLiATKOcfGho60ndgFBb+ISKB2tnbT3hPXEb+ISK7oH9GTrhO7oOAXEQlUuodygoJfRCRQG+rbKS+MUV1akLYyFfwiIgHqn6PHj4uqD0fBLyISoI0N6R3KCQp+EZHANHf2sru9V8EvIpIrNjak/8QuKPhFRAIzMKKnuiyt5Sr4RUQCsqG+nYJYhJmVRWktV8EvIhKQDfXtLKguJRpJ34geUPCLiARmQwAjekDBLyISiO6+BHVNXWmdnK2fgl9EJAAbG9pxLv0jekDBLyISiCDm6Omn4BcRCcDG+nYiBvOqitNetoJfRCQAGxramTulhIJYNO1lK/hFRALw+o42DgugmwcU/CIiabenvYe3d3dwwtzKQMpX8IuIpNmqLc0ALFbwi4jkhtrNjeRFjXfNrAikfAW/iEiardrcxKKZFRTmpf/ELij4RUTSqjee5OW6FhbPCaabBxT8IiJptXZ7C73xJDXzFPwiIjlh1eYmgMBG9ICCX0QkrWo3NTFncjFTywoDq4OCX0QkTZxzrNzSFNgwzn4KfhGRNNna2EVDW4+CX0QkV6zc0ggE98Otfgp+EZE0Wbm5ibKCGIdPS+/F1YfyLfjNbKmZ1ZvZ2v28dr2ZOTOr8qt8EZFMU7upiePmTEr7NXaH8vOI/w7ggqELzWw2cB6wxceyRUQySlt3H2/sagu8mwd8DH7n3DNA435eugX4GuD8KltEJNO8tKUZ56Bm7uSgq5LePn4z+xCwzTn38gjWvcbMas2stqGhIQ21ExHxz8rNTUQMjpszKeiqpC/4zawYuAH415Gs75y7zTlX45yrqa6u9rdyIiI+W7m5iSOnl1NaEAu6Kmk94l8IzAdeNrNNwCxglZlNT2MdRETSLpF0vJQBP9zql7Zdj3PuFWBq/3Mv/Gucc7vTVQcRkSDUNXXS0Ztg0czyoKsC+DuccxmwHDjCzOrM7Gq/yhIRyWR1TV0AzJ5cHHBNUnw74nfOXX6Q1+f5VbaISCapa+oEYHZlZgS/frkrIuKzuqYuohFjRkVwM3IOpuAXEfFZXVMX08sLiUUzI3IzoxYiIlmsrqmTWZVFQVdjgIJfRMRndU1dzMqQ/n1Q8IuI+Ko3nmRna7eO+EVEcsX25i6cQ8EvIpIr+sfwq6tHRCRH9I/h1xG/iEiOyLQx/KDgFxHxVV1TJzMqMmcMPyj4RUR8lRrKmTndPKDgFxHxVaaN4QcFv4iIb3riCXa1ZdYYflDwi4j4ZntztzeGX0f8IiI5IROHcoKCX0TEN5l2AZZ+Cn4REZ/UNXUSixjTygqCrso+FPwiIj6pa+pixqTMGsMPCn4REd/UNXUxa1JmdfOAgl9ExDeZdgGWfgp+EREf9MQT7GrtybihnKDgFxHxxfbmbiDzhnKCgl9ExBdbGzNzDD8o+EVEfJGpY/hBwS8i4ouBMfzlmTMPfz8Fv4iID+qaujhkUhHRiAVdlXdQ8IuI+CBTh3KCgl9ExBeZeAGWfgp+EZEJ1t2XoL4tM8fwg4JfRGTCbW9OjejJ1CP+WNAVEBEJu40N7Tz5ej1J50g62DIwhj8zj/gV/CIi43TLY2/y5zU79llWXhjjsKmlAdXowBT8IiLj1NLVx7GzKrjnMycTMcMM8qKRjBzKCSPs4zezhWZW4D0+y8y+aGaT/K2aiEg4tHbHqSjOp6QgRlF+lMK8aMaGPoz85O4DQMLMDgV+B8wH7vGtViIiIdLW3UdZQXg6UEYa/EnnXBy4GPixc+7LwAz/qiUiEh5t3XHKCrMv+PvM7HLgSuDP3rI8f6okIhIu7Vka/J8ETgFudM69bWbzgbsO9AYzW2pm9Wa2dtCyH5jZOjNbY2Z/1HkCEQm7vkSSrr4EZYXhORYeUfA7515zzn3RObfMzCqBMufcTQd52x3ABUOWPQYscs69G3gT+MZoKywikknau+MAlGZbH7+ZPWVm5WY2GXgZuN3MfnSg9zjnngEahyx71DtXAPA8MGsMdRYRyRhtXvBnY1dPhXOuFfgwcLtzbjFw7jjL/hTw8HAvmtk1ZlZrZrUNDQ3jLEpExB+t3X0A2dfVA8TMbAbwUfae3B0zM7sBiAN3D7eOc+4251yNc66murp6vEWKiPiivSd1xF+ehUf83wb+Cmx0zr1oZguA9WMp0MyuBD4I/LNzzo3lM0REMsXerp7wHPGPaBflnLsPuG/Q87eAS0ZbmJldAPwLcKZzrnO07xcRyTRtXldPabYd8ZvZLG/4Zb2Z7TKzB8zsgCdmzWwZsBw4wszqzOxq4GdAGfCYma02s1+NuwUiIgEK48ndkdb0dlJTNFzqPb/CW3becG9wzl2+n8W/G1XtREQyXH8ff5iCf6R9/NXOududc3HvdgegM64ikvNau/vIj0UoiEWDrsqIjTT4d5vZFWYW9W5XAHv8rJiISBi0dcdDNaIHRh78nyI1lHMnsAP4CKlpHEREclpbdzxUv9qFkU/ZsMU59yHnXLVzbqpz7iJSP+YSEclpbd19oRrKCeO72PpXJqwWIiIhFbaZOWF8wZ+5l5cREUmTsM3FD+MLfv3qVkRyXhi7eg64mzKzNvYf8AYU+VIjEZEQCePJ3QPW1jlXlq6KiIiETTLpaO/N3uGcIiIyREdvHOfCNUEbKPhFRMYsjPP0gIJfRGTMwjglMyj4RUTGLIxTMoOCX0RkzNTVIyKSY9pCeNlFUPCLiIxZWwgvtA4KfhGRMevv6gnbD7gU/CIiY9TW3Uc0YhTnh+ciLKDgFxEZs3ZvugazcM1ZqeAXERmjMM7MCQp+EZExa+2Oh+7ELij4RUTGrK27j7KQndgFBb+IyJipq0dEJMe09yj4RURyShivvgUKfhGRMXHOqatHRCSXdPcliSdd6GbmBAW/iMiYhHWeHlDwi4iMSVhn5gQFv4jImIR1Ln5Q8IuIjIm6ekREckxYp2QGBb+IyJjsPeJX8IuI5IS9ffzq6hERyQnq6hERyTFt3XFK8qNEI+G6CAso+EVExiSs8/SAgl9EZEzCOjMn+Bj8ZrbUzOrNbO2gZZPN7DEzW+/dV/pVvoiIn8I6QRv4e8R/B3DBkGVfB55wzh0GPOE9FxEJHXX17Idz7hmgccjiC4E7vcd3Ahf5Vb6IiJ/auuOhnJkT0t/HP805twPAu5863Ipmdo2Z1ZpZbUNDQ9oqKCIyEq3d8VBO0AYZfHLXOXebc67GOVdTXV0ddHVERPbR3qOunpHaZWYzALz7+jSXLyIybn2JJN19ScpC+OMtSH/w/wm40nt8JfBfaS5fRGTcwjwlM/g7nHMZsBw4wszqzOxq4CbgPDNbD5znPRcRCZX+CdpKQ9rV49vuyjl3+TAvvdevMkVE0kFH/CIiOUbBLyKSY/q7espD2tWj4BcRGSUd8YuI5JiBk7sazikikhvCfPUtUPCLiIxae0+cgliE/Fg4IzSctRYRCVBrdzy0R/ug4BcRGbW27r7QTtAGCn4RkVEL85TMoOAXERm1MF92ERT8IiKj1tbdR1mB+vhFRHJCXyJJS1dfqI/4w1tzEZE0SCYdz23czQtvNbJycxOrtzbT1Zegqqwg6KqNmYJfRGQYW/Z08i8PrGH5W3uIRoyjZ5TzsSWzWTy3knOPmhZ09cYsq4O/saOXtu4+kg6SzuEcOOdw3uvOgSO1vP/1/ntgYD0D8mMRCmIRCvKi5EcjRAzMDAMiZqmVBvM+K+kciVRBmBkRg2jEiESMqFnq8cB9ah0RCVYy6bhz+Sa+/8gbRCPGjRcv4qLjZlIS0ikahsqOVgzjR4+9wV3Pbwm6GmMyOP/7d0T9yyO2dycRGXieehyLRsiPRijIiwz8sjA/6t3HouRH9+5s+ndYsYgNrJMXTb0vGjFi0QixiBGL7vv63s9L3Qq88vKj0X3KLYxFKcyLUhCLEIlohyaZr7mzl9pNTfzq6Y3Ubm7i7COqufHid3HIpKKgqzahsjr4LzlhFifMqSRihg06Qk/lXSqIUkHaH6KDXvdyyjCSztEbT9ITT3r3CZKDvj0k3f7LjxpEIjZQriN1JJFIuoFvA/Gk85Z53zZgIOkdg75I9FfIuYFvMP3fJJJu7/vjyeSQuqbue+NJWrv66I0nB8oe+JykG1inN5G6TyRTdZsoBbEIRflRivOiFOVHKSmIUZQXpbQgRklBjJKCKCX5qcelBTFKC1OPywtjlBflUVGUR3lhHuVFMQpi0Qmrl8iKtxv540vbqN3UyPr6dgAqivL40UeP5eLjZ2blt/CsDv7j51Ry/JzKoKsRWs7bKcSTbmCH0H/rS3g7lcTQHU2C3njqQtQ98QRdfYnU477U487eBF29CTp743T0JtjZ2k1nb4L2njgdPXE6exMHrVdhXoQKb2cwqSifScV5VBan7if13xflUVGcer3Ce16cH83K/8Qydi9uauSK375AQV6ExXMruej4mdTMreTY2ZMozMveA4ysDn4ZH7NUN08sStr+EySSLrVT6EnQ3tNHS1ec1u4+WrtSt5Yht+bOPjbv6WT11maaO/voTSSH/ey8qKV2FsX5TC7Op7Ikj8kl+YOe5zO5JLUTmVJSwJTSfO0sstjmPR1c8/taZlUW8eC1pzKpOD/oKqWNgl8ySjRilBXmeRNgFY7qvc45OnsTAzuE1M6hd+B5c/99Zy9Nnb1s2t3Jqi3NNHX0DtutVZgXYUpJAVWl+UwpTd1XlRZQVVrA1PICppYVMrUs9bg4X/+dMkVTRy8vbmpkxduN7Gjt5qpT57Fk3uSB11s6+/jkHS/igN9dtSSnQh8U/JJFzMw7XxAb1ck45xxtPXGaO/po7OylsaOHPe297OnopbGjl91tPezu6GVnSzdrt7Wwp6OXxH52FGUFMarLC5hWVsjU8gKmlRcyrbyQ6eWFTK8oYEZFEVPLCohF9btJv/z11Z386NE3eWNXG5A6t1ScH+Uva3Zw7lHT+Pr7j2DulBI+d/dKtjZ2ctfVJzG/qiTgWqefgl9ynpmlThwX5jFnSvFB108mHc1dfdS3dVPf2kN9W8+gx6n7VVua2NXaQ298366naMSYVlbAjElFHDKpiEMmFTJr4HERsycXh/aqTkHrjSf55n+upawgxlfPP4IT50/m3bMqSCZh6XNv88unNvK+W57hyOnlvLajlR9eeiwnLZgSdLUDob8wkVGKRIzJJflMLsnnyOnDr+eco6mzj50t3exq7WZHSzfbm7vY3tLF9uYuVm9t4pG13fQl9v32MKUkn9mTi5kzuZj5VSUcOrWUw6aVMr+qRCOaDuC/X9lBQ1sPN196LGceXr3Pa58/+1AuWzKbnz65gbtf2MwX33sYlyyeFVBNg2fOTdyQPb/U1NS42traoKshMuGSScfu9h62NXexrbmLrY1dbGnsZEtjB5v3dLKtuWvgdxwRg3lTSjhqRjlHH1LO0d79tPLRnQvJVhf+/Dnauvt4/MtnHvB3Iz3xRM7sQM1spXOuZuhyHfGLBCgSMaaWFzK1vHC/Q4+7+xK81dDB+vo2Nta3s25nG2u2NfOXV3YMrLOgqoTTD6vi9MOqOXnhlJzsKlq1pYmXtzbznQuPOeiPBXMl9A8k9/5CREKkMC+aOro/pHyf5a3dfazb0caaumae3bCbe2vruHP5ZmIR46wjqrn8xDmceXh1zpxIvv25TZQVxvjwCbnbfTMaCn6RECovzOPE+ZM5cf5kPn36AnriCVZubuLpNxp48KVtPP56LTMqCvlozWwuO3E2Myqya8qBwXa2dPPwKzu46tR5WTOXjt/0rySSBQpiUU5dWMWpC6u4/vwjeOL1epat2MJPnlzPL5/eyJWnzOXzZx+alePV73p+MwnnuPLUeUFXJTQU/CJZJi8a4YJF07lg0XS2NnZy6xPr+e2zb/OHF7dy7VmH8snT5mXNdATdfQnuWbGFc4+axuzJBx+KKym50QEokqNmTy7m5kuP5eH/dTpL5k3me4+s45ybn+L5t/YEXbUJ8aeXt9PY0csnT5sXdFVCRcEvkgOOnF7O0quW8IdrTqYwL8rHf/M8P378zf3+AjksnHPc/twmjphWxik5+kOssVLwi+SQkxdM4U/XvYcLj5vJjx9fzxW/fYFdrd1BV2tMnnqzgdd3tHL16fM1kd4oKfhFckxpQYwfffRYfvCRd7N6azMfuPXv/GPj7qCrNSrOOX76xHpmTiri4uNnBl2d0FHwi+QgM+PSmtk8dN1pVJbk84nfreDe2q1BV2vElr+1h1VbmvnsmQvIy5HfKkwk/YuJ5LBDp5bxwOdO5ZSFU/ja/Wv43iPrSIag3//nf9tAdVkBl9bMDroqoaTgF8lxFUV5LL1qCR8/aQ6/fGojX1i2iu6+g18JLSgrNzfx3IY9/M8zFmTNsNR0U/CLCHnRCDdetIhv/tNRPLx2J5fd9jy723uCrtZ+/fxvG6gszuPjJ80JuiqhFUjwm9mXzexVM1trZsvMTNMLigTMzPj06Qv41RWLWbezlQ//4h+81dAedLX2sXZbC0+uq+fq98zXFc/GIe3Bb2YzgS8CNc65RUAUuCzd9RCR/Tv/mOks+8zJdPTEueSX/2Dl5sagqzTg53/bQFlhjE9oeoZxCaqrJwYUmVkMKAa2B1QPEdmP4+dUDlyA/PLfvMB/D5oGOgjxRJLbn3ubR17dyZWnzKO8MC/Q+oRd2oPfObcNuBnYAuwAWpxzjw5dz8yuMbNaM6ttaGhIdzVFct7cKSU88LlTWXRIOdfevYpbH18/5hE/e9p7+P3yTexo6XrHa/FEkntf3MppNz3JaTc9yU+eWM/Olr0/KntxUyMf/OmzfOuh13jPoVV85owFY22SeNJ+BS4zqwQeAD4GNAP3Afc75+4a7j26ApdIcLr7EvzvP77Cg6u2cf4x0/jhR48b1cVeunoTXHbbcl6uayFicM6RU/n4SXM447BqHn+9npsffYMN9e0cO3sSZQUxnt2w21tvGiUFUf5r9XYOqSjkmx88mvcvmq5f6Y5CJl2B61zgbedcA4CZPQicCgwb/CISnMK8KD+89FiOOaSCG//yGh/+xXP85hM1zJ1SctD3JpOOr9y7mjXbWvjuh9/F1sZO7q2t4/HXayktiNHeE2dhdQm/umIx5x8zDTNj854O/vDiVu6rraOlq5drz1rIF845VCdzJ1AQR/wnAUuBJUAXcAdQ65z76XDv0RG/SGZ4dv1uvrBsFc7B9z/ybs4/5gBXmwe++/Dr/Prpt/jmPx3Fp09PddH0xpM89touHn1tJ6cunMIlJ8za75XC+hJJeuLJnLyU5EQZ7og/kIutm9m3SHX1xIGXgE8754YdNKzgF8kcW/Z0cu09K1m7rZWP1czm//yPo/cbzstWbOEbD77CFSfP4TsXLlIXTQAyKvhHS8Evkll640lufeJNfvHURmZXFnPLx47jhDmTqG/r4a2GDl7d3sJND6/jtEOr+N2VNTlz7d9Mo+AXkQm34u1Gvvz/VrOjpYuivCgdvXunenjXzAru+cxJlGnoZWAy6eSuiGSJE+dP5pEvnc7P/7aR7r4EC6pLWFBVyvzqEmaUFxKJqHsnEyn4RWRcygrz+Pr7jwy6GjIK6ngTEckxCn4RkRyj4BcRyTEKfhGRHKPgFxHJMQp+EZEco+AXEckxCn4RkRwTiikbzKwB2DxkcQXQcpBlB3re/3jwsipg9ziqur86jWadkbRp6LKDPR5vm4arw2jWmahtNfhxOrbVgdYb6fLRbCsIx99gLmyroc/DmhdznXPV73incy6UN+C2gy070PP+x0OW1U50nUazzkjaNFw7DtC+cbUpXe0aybaayHaNpE0HWm+ky0ezrdLVLm2rsbcrbNtquFuYu3oeGsGyAz1/aJh1xmMkn3WgdUbSpqHLRvJ4vNLRrpFsq5HWZSRG+jnDrTfS5dpW4xfEthr6PMx58Q6h6OpJFzOrdfuZyS7MsrFNoHaFSTa2CcLdrjAf8fvhtqAr4INsbBOoXWGSjW2CELdLR/wiIjlGR/wiIjlGwS8ikmOyNvjNbKmZ1ZvZ2jG8d7GZvWJmG8zsJzboKtFmdp2ZvWFmr5rZ9ye21get14S3ycz+3cy2mdlq7/aBia/5Qevmy7byXr/ezJyZVU1cjUdULz+21XfMbI23nR41s0MmvuYHrZsf7fqBma3z2vZHM5s08TU/aN38aNelXk4kzSyzTgKPZxxqJt+AM4ATgLVjeO8K4BTAgIeB93vLzwYeBwq851OzoE3/DlyfbdvKe2028FdSP/6rCnubgPJB63wR+FU2bCvgfUDMe/w94HtZ0q6jgCOAp4CadLfpQLesPeJ3zj0DNA5eZmYLzewRM1tpZn83s3dcL87MZpD6D7bcpbbe74GLvJc/B9zknOvxyqj3txX78qlNgfOxXbcAXwPSPoLBjzY551oHrVpC9rTrUedc3Fv1eWCWv614J5/a9bpz7o101H+0sjb4h3EbcJ1zbjFwPfCL/awzE6gb9LzOWwZwOHC6mb1gZk+b2RJfazsy420TwBe8r9lLzazSv6qOyrjaZWYfArY55172u6KjMO5tZWY3mtlW4J+Bf/WxrqMxEX+D/T5F6qg5E0xkuzJKzlxs3cxKgVOB+wZ1Axfsb9X9LOs/sooBlcDJwBLgXjNb4O3p026C2vRL4Dve8+8APyT1ny8w422XmRUDN5DqQsgIE7StcM7dANxgZt8AvgD82wRXdVQmql3eZ90AxIG7J7KOYzGR7cpEORP8pL7dNDvnjhu80MyiwErv6Z9IBeHgr5qzgO3e4zrgQS/oV5hZktRETQ1+VvwAxt0m59yuQe/7DfBnPys8QuNt10JgPvCy9592FrDKzE50zu30ue7DmYi/v8HuAf5CwMHPBLXLzK4EPgi8N6gDqSEmentllqBPMvh5A+Yx6GQN8A/gUu+xAccO874XSR3V95+s+YC3/LPAt73HhwNb8X4EF+I2zRi0zpeBP2TDthqyzibSfHLXp2112KB1rgPuz4ZtBVwAvAZUB9Eev/8GycCTu4FXwMeNuAzYAfSROlK/mtRR4CPAy94f2r8O894aYC2wEfhZf7gD+cBd3murgHOyoE3/F3gFWEPqCGZGutrjZ7uGrJP24PdpWz3gLV9DajKumdmwrYANpA6iVnu3IEYr+dGui73P6gF2AX9Nd7uGu2nKBhGRHJNro3pERHKegl9EJMco+EVEcoyCX0Qkxyj4RURyjIJfQsnM2tNc3m/N7OgJ+qyEN8PmWjN76GCzUZrZJDO7diLKFgFdgUtCyszanXOlE/h5Mbd3ojBfDa67md0JvOmcu/EA688D/uycW5SO+kn20xG/ZA0zqzazB8zsRe92mrf8RDP7h5m95N0f4S2/yszuM7OHgEfN7Cwze8rM7vfmh7970NzqT/XPqW5m7d5kaS+b2fNmNs1bvtB7/qKZfXuE30qWs3diuVIze8LMVllqfvcLvXVuAhZ63xJ+4K37Va+cNWb2rQn8Z5QcoOCXbHIrcItzbglwCfBbb/k64Azn3PGkZrT8j0HvOQW40jl3jvf8eOBLwNHAAuC0/ZRTAjzvnDsWeAb4zKDyb/XKP+h8Ld68L+8l9YtpgG7gYufcCaSu/fBDb8fzdWCjc+4459xXzex9wGHAicBxwGIzO+Ng5Yn0y6VJ2iT7nQscPWg2xXIzKwMqgDvN7DBSMyfmDXrPY865wfOwr3DO1QGY2WpS87c8O6ScXvZOZrcSOM97fAp7rwdwD3DzMPUsGvTZK4HHvOUG/IcX4klS3wSm7ef97/NuL3nPS0ntCJ4ZpjyRfSj4JZtEgFOcc12DF5rZT4G/Oecu9vrLnxr0cseQz+gZ9DjB/v+P9Lm9J8eGW+dAupxzx5lZBakdyOeBn5CaY78aWOyc6zOzTUDhft5vwHedc78eZbkigLp6JLs8SmqOegDMrH9K3Qpgm/f4Kh/Lf55UFxPAZQdb2TnXQuoSiufT9wgAAADUSURBVNebWR6petZ7oX82MNdbtQ0oG/TWvwKf8uaMx8xmmtnUCWqD5AAFv4RVsZnVDbp9hVSI1ngnPF8jNY02wPeB75rZc0DUxzp9CfiKma0AZgAtB3uDc+4lUrM/XkbqAiQ1ZlZL6uh/nbfOHuA5b/jnD5xzj5LqSlpuZq8A97PvjkHkgDScU2SCeFf+6nLOOTO7DLjcOXfhwd4nkm7q4xeZOIuBn3kjcZoJ+BKWIsPREb+ISI5RH7+ISI5R8IuI5BgFv4hIjlHwi4jkGAW/iEiO+f9jLhcakeZafgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>seq2seq_acc</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.702562</td>\n",
       "      <td>3.286544</td>\n",
       "      <td>0.571327</td>\n",
       "      <td>0.309566</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.528624</td>\n",
       "      <td>2.187998</td>\n",
       "      <td>0.623373</td>\n",
       "      <td>0.450276</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.677970</td>\n",
       "      <td>1.979097</td>\n",
       "      <td>0.638976</td>\n",
       "      <td>0.506280</td>\n",
       "      <td>01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.642650</td>\n",
       "      <td>1.575299</td>\n",
       "      <td>0.689907</td>\n",
       "      <td>0.524269</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.382120</td>\n",
       "      <td>1.480329</td>\n",
       "      <td>0.710863</td>\n",
       "      <td>0.555965</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.197429</td>\n",
       "      <td>1.439226</td>\n",
       "      <td>0.718752</td>\n",
       "      <td>0.567122</td>\n",
       "      <td>01:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, 3e-3)\n",
    "learn.export('/home/jupyter/data/translation_fastai_seq2seq_export.pkl')\n",
    "learn.save('/home/jupyter/data/translation_fastai_seq2seq_learn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='425' class='' max='425', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [425/425 00:53<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets, outputs = get_predictions(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos quels sont les aliments qu'on mange habituellement avec de la sauce de soja   ?,\n",
       " Text xxbos what are some foods you usually eat with soy sauce ?,\n",
       " Text xxbos what are some foods you usually usually with with with ?)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[700],targets[700],outputs[700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos j'ai écouté mais je n'ai pas pu distinguer ce qu'ils xxunk .,\n",
       " Text xxbos i listened but could n't make out what they were saying .,\n",
       " Text xxbos i listened to . , i could n't n't n't help them .)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[2513], targets[2513], outputs[2513]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text xxbos il y a beaucoup de tremblements de terre au japon .,\n",
       " Text xxbos we have a lot of earthquakes in japan .,\n",
       " Text xxbos there are many lot of japan in japan)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[4000], targets[4000], outputs[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Exception ignored in: \n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "<function _ConnectionBase.__del__ at 0x7f91ce600440>\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 263, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n",
      "    self._close()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=Seq2SeqDataBunch;\n",
       "\n",
       "Train: LabelList (0 items)\n",
       "x: Seq2SeqTextList\n",
       "\n",
       "y: TextList\n",
       "\n",
       "Path: /home/jupyter/data;\n",
       "\n",
       "Valid: LabelList (0 items)\n",
       "x: Seq2SeqTextList\n",
       "\n",
       "y: TextList\n",
       "\n",
       "Path: /home/jupyter/data;\n",
       "\n",
       "Test: None, model=Seq2SeqRNN_tf(\n",
       "  (emb_enc): Embedding(10464, 300, padding_idx=1)\n",
       "  (emb_enc_drop): Dropout(p=0.15, inplace=False)\n",
       "  (gru_enc): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (out_enc): Linear(in_features=256, out_features=300, bias=False)\n",
       "  (emb_dec): Embedding(6512, 300, padding_idx=1)\n",
       "  (gru_dec): GRU(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (out_drop): Dropout(p=0.35, inplace=False)\n",
       "  (out): Linear(in_features=300, out_features=6512, bias=True)\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=<function seq2seq_loss at 0x7f8f48e3ee60>, metrics=[<function seq2seq_acc at 0x7f8f47552830>, CorpusBLEU\n",
       "vocab_sz: 6512], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/jupyter/data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), functools.partial(<class '__main__.TeacherForcing'>, end_epoch=3)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Embedding(10464, 300, padding_idx=1)\n",
       "  (1): Dropout(p=0.15, inplace=False)\n",
       "  (2): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
       "  (3): Linear(in_features=256, out_features=300, bias=False)\n",
       "  (4): Embedding(6512, 300, padding_idx=1)\n",
       "  (5): GRU(300, 300, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (6): Dropout(p=0.35, inplace=False)\n",
       "  (7): Linear(in_features=300, out_features=6512, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#learn = load_learner('/home/jupyter/data/', 'translation_fastai_seq2seq_export.pkl')\n",
    "#@doc(Learner)\n",
    "learn.load('/home/jupyter/data/translation_fastai_seq2seq_learn')\n",
    "#pred = learn.predict(learn.data.train_ds)\n",
    "\n",
    "##print(df['fr'].iloc[66])\n",
    "#print(inputs[1], t)\n",
    "#inputs[4000], targets[4000], outputs[4000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
